import torch
import openai
from protocol import LogicSynapse
from sentence_transformers import SentenceTransformer
import bittensor as bt
from concurrent import futures

SIMILARITY_WEIGHT = 0.4
CORRECTNESS_WEIGHT = 0.6
PROCESSING_TIME_WEIGHT = -0.1


class LogicRewarder:
    def __init__(self, base_url: str, api_key: str, model: str):
        """
        READ HERE TO LEARN HOW VALIDATOR REWARD THE MINER
        """
        bt.logging.info(
            f"Logic Rewarder initialized with model: {model}, base_url: {base_url}"
        )
        self.openai_client = openai.OpenAI(base_url=base_url, api_key=api_key)
        self.model = model
        self.embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

    def __call__(self, response: LogicSynapse, base_synapse: LogicSynapse):                
    
        ref_ground_truth: str = self._get_ground_truth(
            base_synapse.raw_logic_question
        )
        response_text = response.logic_reasoning
        similarity = self._get_similarity(ref_ground_truth, response_text)
        correctness = self._get_correctness(base_synapse, response)

        process_time = response.process_time
        timeout = base_synapse.timeout
        
        reward = (
            SIMILARITY_WEIGHT * similarity
            + CORRECTNESS_WEIGHT * correctness
            + PROCESSING_TIME_WEIGHT * min(process_time / timeout, 1)
        )
        # Scale up the reward
        reward = reward / 2 + 0.5
        print(
            f"[REWARDER] similarity: {similarity}, correctness: {correctness}, processing time: {process_time}"
        )
        return similarity, correctness, reward

    def _get_correctness(
        self, base_synapse: LogicSynapse, response: LogicSynapse
    ):
        """Ask LLM to rate the correctness of the answer based on raw logic question and ground truth

        Args:
            base_synapse (LogicSynapse): _description_
            responses (list[LogicSynapse]): _description_

        Returns:
            list[bool]: list of correctness rating for each response
        """
        ground_truth_answer = base_synapse.ground_truth_answer
        print("="*100)
        print(response.logic_answer)
        print(f"[CORRECTNESS] Ground truth: {ground_truth_answer}")
        print("="*100)
        messages = [
            {
                "role": "user",
                "content": f"{base_synapse.raw_logic_question}\n The ground truth is {ground_truth_answer}\n\n Your task is rate the correctness of this answer into 'correct' or 'incorrect'. The correct answer need have numerical or reasoning nearly equivalent to ground truth above. Just say your rating, don't reasoning anymore!.\n---{response.logic_answer}\n---",
            },
        ]
               
        correctness = []
        # USE OPENAI API TO RATE THE ANSWER
    
        result = self.openai_client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=32,
                temperature=0.7,
            )
        
        response_str = result.choices[0].message.content
        response_str = response_str.strip().lower()
        print(f"[CORRECTNESS] Rating: {response_str}")
        if "incorrect" in response_str:
            correctness = 0
        elif "correct" in response_str:
            correctness = 1
        else:
            correctness = 0.3
        return correctness

    def _get_similarity(self, ground_truth: str, response: str):
        """Calculate cosine similarity between self-generate ground truth and miner response

        Args:
            ground_truth (str): groud_truth generated by self
            responses (list[str]): list of responses from miners

        Returns:
            list[float]: list of similarity score for each response
        """
        ground_truth_embedding = self.embedder.encode(ground_truth)
        responses = [response]
        response_embeddings = self.embedder.encode(responses)

        # calculate similarity
        response_embedding = response_embeddings[0]
        
        similarity = torch.nn.functional.cosine_similarity(
            torch.tensor(ground_truth_embedding),
            torch.tensor(response_embedding),
            dim=0,
        )
        
        return similarity.item()

    def _get_ground_truth(self, question: str):
        """Generate self-generate ground truth based on the question

        Args:
            question (str): raw logic question

        Returns:
            str: self-generate ground truth
        """
        messages = [
            {"role": "user", "content": question},
        ]
        response = self.openai_client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=1024,
            temperature=0.7,
        )
        response = response.choices[0].message.content
        
        return response
